# GILA (Global Interaction and Local Alignment)

This is the code implementation for paper [Cross-Modal Global Interaction and Local Alignment for Audio-Visual Speech Recognition](https://arxiv.org/abs/2305.09212) that is built based on [AV-HuBERT](https://github.com/facebookresearch/av_hubert) and [Fairseq](https://github.com/facebookresearch/fairseq) toolkit.
